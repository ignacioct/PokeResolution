{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings and info\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import PIL\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from wandb.keras import WandbCallback\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "from matplotlib.figure import Figure\n",
    "from IPython.display import Image\n",
    "\n",
    "from data import Images\n",
    "from utils import TrackTraining\n",
    "from models.edsr import edsr\n",
    "from models.srcnn import srcnn\n",
    "from models.fsrcnn import fsrcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_HIGHRES = './images/original/'\n",
    "DIR_SPLITS = './images/'\n",
    "WEIGHTS_DIR = './weights/'\n",
    "RESULTS_DIR = './results/'\n",
    "SAVED_DIR = './saved/'\n",
    "CREATE_FOLDERS = True # Creates folder splits the first time\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "FACTOR = 4  # 2-4\n",
    "INPUT_SIZE = 256//FACTOR\n",
    "REPEAT_COUNT = 10  # Data Augmentation\n",
    "RGB = True # If false, only Y channel (luminance) in YUV is used\n",
    "CHANNELS = 3 if RGB else 1\n",
    "\n",
    "EPOCHS = 20\n",
    "LOSS = 'mean_absolute_error'\n",
    "MODEL = 'edsr'\n",
    "MODEL_NAME = f'{MODEL}-x{FACTOR}-a{REPEAT_COUNT}-c{CHANNELS}-e{EPOCHS}-{LOSS}'\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# SRCNN\n",
    "if MODEL == 'srcnn':\n",
    "    model = srcnn(factor=FACTOR, channels=CHANNELS)\n",
    "    model_trained = srcnn(factor=FACTOR, channels=CHANNELS)\n",
    "\n",
    "# FSRCNN\n",
    "elif MODEL == 'fsrcnn':\n",
    "    model = fsrcnn(factor=FACTOR, channels=CHANNELS)\n",
    "    model_trained = fsrcnn(factor=FACTOR, channels=CHANNELS)\n",
    "\n",
    "# EDSR baseline from https://arxiv.org/abs/1707.02921\n",
    "elif MODEL == 'edsr':\n",
    "    model = edsr(factor=FACTOR, residual_scaling=None, channels=CHANNELS)\n",
    "    model_trained = edsr(factor=FACTOR, residual_scaling=None, channels=CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/Users/ignacio/opt/anaconda3/envs/test_2/lib/python3.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mignacioct\u001b[0m (\u001b[33mastro-res\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ignacio/Documents/DeepLearningVisualRecognition/PokeResolution/wandb/run-20221208_221805-1fdrs1te</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/astro-res/AstroRes/runs/1fdrs1te\" target=\"_blank\">olive-hill-81</a></strong> to <a href=\"https://wandb.ai/astro-res/AstroRes\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init()\n",
    "wandb.run.name = MODEL_NAME\n",
    "config = wandb.config\n",
    "config.batch_size = BATCH_SIZE\n",
    "config.factor = FACTOR\n",
    "config.input_size = INPUT_SIZE\n",
    "config.repeat_count = REPEAT_COUNT\n",
    "config.rgb = RGB\n",
    "config.epochs = EPOCHS\n",
    "config.loss = LOSS\n",
    "config.model = MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splits of high resolution images\n",
    "Generate splits and obtain dataset of high resolution images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 655 files belonging to 1 classes.\n",
      "Found 81 files belonging to 1 classes.\n",
      "Found 83 files belonging to 1 classes.\n",
      "High res images: 655 (training), 81 (validation), 83(test)\n"
     ]
    }
   ],
   "source": [
    "images = Images(path=DIR_HIGHRES, split_path=DIR_SPLITS)\n",
    "train_ds, val_ds, test_ds = images.get_high_res_partitions(createFolders=CREATE_FOLDERS)\n",
    "print(f'High res images: {len(train_ds)} (training), {len(val_ds)} (validation), {len(test_ds)}(test)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use only Y channel from YUV model (luminance) if RGB is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processs_input(input):\n",
    "    input = tf.image.rgb_to_yuv(input)\n",
    "    last_dimension_axis = len(input.shape) - 1\n",
    "    y, u, v = tf.split(input, 3, axis=last_dimension_axis)\n",
    "    return y, u, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RGB:\n",
    "    train_ds = train_ds.map(lambda x: processs_input(x)[0])\n",
    "    val_ds = val_ds.map(lambda x: processs_input(x)[0])\n",
    "    test_ds = test_ds.map(lambda x: processs_input(x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display some images from train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "for i, image in enumerate(train_ds.take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    if not RGB:\n",
    "        plt.imshow(image.numpy().astype(\"uint32\"), cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(image.numpy().astype(\"uint32\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  tf.keras.layers.RandomRotation(0.5),\n",
    "])\n",
    "\n",
    "if REPEAT_COUNT > 0:\n",
    "  augmented_train_ds = train_ds.concatenate(train_ds.map(data_augmentation, num_parallel_calls=AUTOTUNE))\n",
    "  for _ in range(REPEAT_COUNT-1):\n",
    "      augmented_train_ds = augmented_train_ds.concatenate(train_ds.map(data_augmentation, num_parallel_calls=AUTOTUNE))\n",
    "  train_ds = augmented_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'High res images: {len(train_ds)} (training), {len(val_ds)} (validation), {len(test_ds)}(test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "for i, image in enumerate(train_ds.skip(1000).take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    if not RGB:\n",
    "        plt.imshow(image.numpy().astype(\"uint32\"), cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(image.numpy().astype(\"uint32\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low resolution images\n",
    "Obtain low resolution image for each high resolution image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scales down images using bicubic downsampling.\n",
    "def downscale_image(image, input_size=INPUT_SIZE):\n",
    "    return tf.clip_by_value(tf.image.resize(\n",
    "        image,\n",
    "        [input_size, input_size],\n",
    "        method=tf.image.ResizeMethod.BICUBIC,\n",
    "        antialias=True\n",
    "    ), 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda x: (downscale_image(x), x))\n",
    "val_ds = val_ds.map(lambda x: (downscale_image(x), x))\n",
    "test_ds = test_ds.map(lambda x: (downscale_image(x), x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display some pairs of images from train dataset with high and low resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i, image in enumerate(train_ds.take(4)):\n",
    "    plt.subplot(4, 2, 2*i+1)\n",
    "    if not RGB:\n",
    "        plt.imshow(image[1].numpy().astype(\"uint32\"), cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(image[1].numpy().astype(\"uint32\"))\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(4, 2, 2*i+2)\n",
    "    if not RGB:\n",
    "        plt.imshow(image[0].numpy().astype(\"uint32\"), cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(image[0].numpy().astype(\"uint32\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "Improve performance with cache and prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(BATCH_SIZE).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE).cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss:**   \n",
    "The pixel-wise $L^2$ loss and the pixel-wise $L^1$ loss are frequently used loss functions for training super-resolution models. They measure the pixel-wise mean squared error and the pixel-wise mean absolute error, respectively, between an HR image $I^{HR}$ and an SR image $I^{SR}$. The pixel-wise $L^2$ loss directly optimizes PSNR. Experiments have shown that the pixel-wise $L^1$ loss can sometimes achieve even better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer and scheduler to reduce learning rate every 5,000 steps\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate=1e-4,\n",
    "    decay_steps=5000,\n",
    "    decay_rate=0.9)\n",
    "OPTIMIZER = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Compile and train model (L1 loss)\n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS)\n",
    "model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds, callbacks=[TrackTraining(), WandbCallback()])\n",
    "\n",
    "# Save weights\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "model.save_weights(f'{WEIGHTS_DIR}weights-{MODEL_NAME}.h5')\n",
    "\n",
    "# Save model\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "model.save(f'{SAVED_DIR}model-{MODEL_NAME}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained.load_weights(os.path.join(WEIGHTS_DIR, f'weights-{MODEL_NAME}.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = tf.convert_to_tensor(PIL.Image.open('./images/test/hr/25.jpg'))\n",
    "lr = downscale_image(hr)\n",
    "lr_input = lr\n",
    "if not RGB:\n",
    "    y, cb, cr = processs_input(lr)\n",
    "    lr_input = y\n",
    "lr_batch = tf.expand_dims(lr_input, axis=0)\n",
    "sr = model_trained(lr_batch)[0]\n",
    "sr = tf.clip_by_value(sr, 0, 255)\n",
    "\n",
    "if not RGB:\n",
    "    out_img_cb = tf.image.resize(cb, [sr.shape[0], sr.shape[0]], method=tf.image.ResizeMethod.BICUBIC)\n",
    "    out_img_cr = tf.image.resize(cr, [sr.shape[0], sr.shape[0]], method=tf.image.ResizeMethod.BICUBIC)\n",
    "    sr = tf.concat([sr, out_img_cb, out_img_cr], axis=-1)\n",
    "    sr = tf.clip_by_value(tf.image.yuv_to_rgb(sr), 0, 255)\n",
    "\n",
    "images = [lr, sr, hr]\n",
    "titles = [\"Low Resolution\", \"Super Resolution\", \"High Resolution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain image with LR, SR, and HR\n",
    "fig = Figure(figsize=(40, 10), dpi=300)\n",
    "canvas = FigureCanvasAgg(fig)\n",
    "for i, (image, title) in enumerate(zip(images, titles)):\n",
    "    ax = fig.add_subplot(1, 3, i+1)\n",
    "    ax.imshow(image.numpy().astype(\"uint32\"))\n",
    "    ax.set_title(title)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "# Save and display images\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "fig.savefig(f'{RESULTS_DIR}{MODEL_NAME}.png')\n",
    "Image(filename=f'{RESULTS_DIR}{MODEL_NAME}.png')\n",
    "\n",
    "# Log image into wandb\n",
    "wandb.log({\"test_img\": wandb.Image(f'{RESULTS_DIR}{MODEL_NAME}.png')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring functions PSNR and SSMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(sr, hr):\n",
    "    return tf.image.psnr(\n",
    "        tf.keras.preprocessing.image.img_to_array(sr),\n",
    "        tf.keras.preprocessing.image.img_to_array(hr),\n",
    "        max_val=255)\n",
    "\n",
    "def ssmi(sr, hr):\n",
    "    sr = tf.expand_dims(sr.numpy().astype(\"uint8\"), axis=0)\n",
    "    hr = tf.expand_dims(hr.numpy().astype(\"uint8\"), axis=0)\n",
    "    return tf.image.ssim(sr, hr, max_val=255)[0]\n",
    "\n",
    "def mse(sr, hr):\n",
    "    return np.mean(np.square(hr - sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr_values = []\n",
    "ssmi_values = []\n",
    "mse_values = []\n",
    "for batch in test_ds:\n",
    "    lr_batch = batch[0]\n",
    "    sr_batch = model_trained(lr_batch)\n",
    "    for i in range(len(batch[0])):\n",
    "        sr = sr_batch[i]\n",
    "        hr = batch[1][i]\n",
    "        psnr_values.append(psnr(sr, hr).numpy())\n",
    "        ssmi_values.append(ssmi(sr, hr).numpy())\n",
    "        mse_values.append(mse(sr, hr))\n",
    "\n",
    "avg_psnr = sum(psnr_values)/len(psnr_values)\n",
    "avg_ssmi = sum(ssmi_values)/len(ssmi_values)\n",
    "avg_mse = sum(mse_values)/len(mse_values)\n",
    "\n",
    "print(\"Average PSNR on test:\", avg_psnr)\n",
    "print(\"Average SSMI on test:\", avg_ssmi)\n",
    "print(\"Average MSE on test:\", avg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"PSNR_test\": avg_psnr, \"SSMI_test\": avg_ssmi, \"MSE_test\": avg_mse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "5306b2b412c0acf9e1d9b98335844418a6970455dc0b335f19ebc0daae3e607f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
